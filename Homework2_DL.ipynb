{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e722ef59-2f72-4881-a5b3-a4fa4d1e9cee",
   "metadata": {},
   "source": [
    "Problem 1 (50 pts)\r\n",
    "\r\n",
    "AlexNet is originally proposed for 227*227 image sizes. It may be too complex for the CIFAR-10 dataset, in particular, due to the low resolution of the initial images; try simplifying the model to make the training faster while ensuring that the accuracy stays relatively high. Report the training loss, validation loss, and validation accuracy. Also, report the number of parameters in your modified version of AlexNet and compare it against the number of parameters in the original AlexNet architectures. Here is a good reference guide to AlexNet: https://www.kaggle.com/code/blurredmachine/alexnet-architecture-a-complete-guideLinks to an external site.\r\n",
    "\r\n",
    "Explore the option of applying Dropout techniques for training your customized AlexNet. Compare the training and validation results against the baseline model without any dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b80769-ab10-4706-ba81-664731441b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1,Training Loss: 1.660, Validation Loss: 1.354\n",
      "Epoch 2,Training Loss: 1.277, Validation Loss: 1.098\n",
      "Epoch 3,Training Loss: 1.103, Validation Loss: 1.085\n",
      "Epoch 4,Training Loss: 0.991, Validation Loss: 0.945\n",
      "Epoch 5,Training Loss: 0.911, Validation Loss: 0.913\n",
      "Epoch 6,Training Loss: 0.847, Validation Loss: 0.889\n",
      "Epoch 7,Training Loss: 0.790, Validation Loss: 0.827\n",
      "Epoch 8,Training Loss: 0.756, Validation Loss: 0.811\n",
      "Epoch 9,Training Loss: 0.710, Validation Loss: 0.770\n",
      "Epoch 10,Training Loss: 0.682, Validation Loss: 0.793\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "# Define the simplified AlexNet model\n",
    "class SimplifiedAlexNet(nn.Module):\n",
    "    def __init__(self, use_dropout=False):\n",
    "        super(SimplifiedAlexNet, self).__init__()\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 48, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(48, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5) if use_dropout else nn.Identity(),\n",
    "            nn.Linear(128 * 4 * 4, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5) if use_dropout else nn.Identity(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Transformations for the input data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Downloading and loading CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize the network\n",
    "net = SimplifiedAlexNet(use_dropout=True)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    net.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "\n",
    "\n",
    "    # Validation phase\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    print(f'Epoch {epoch + 1},Training Loss: {avg_train_loss:.3f}, Validation Loss: {avg_val_loss:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de6e893-9a05-4da5-a1c1-7fe07341aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy of the network on the 10000 test images: 72.82%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final Accuracy of the network on the 10000 test images: {final_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d170f6f-357b-4d09-8e23-d492e8eb3735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Training Loss: 1.584, Validation Loss: 1.298\n",
      "Epoch 2,Training Loss: 1.115, Validation Loss: 1.004\n",
      "Epoch 3,Training Loss: 0.896, Validation Loss: 0.882\n",
      "Epoch 4,Training Loss: 0.752, Validation Loss: 0.896\n",
      "Epoch 5,Training Loss: 0.640, Validation Loss: 0.771\n",
      "Epoch 6,Training Loss: 0.543, Validation Loss: 0.822\n",
      "Epoch 7,Training Loss: 0.467, Validation Loss: 0.815\n",
      "Epoch 8,Training Loss: 0.393, Validation Loss: 0.886\n",
      "Epoch 9,Training Loss: 0.335, Validation Loss: 0.933\n",
      "Epoch 10,Training Loss: 0.287, Validation Loss: 0.996\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network\n",
    "net_nodropout = SimplifiedAlexNet(use_dropout=False)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net_nodropout.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net_nodropout.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    net_nodropout.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net_nodropout(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "\n",
    "\n",
    "    # Validation phase\n",
    "    net_nodropout.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = net_nodropout(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    print(f'Epoch {epoch + 1},Training Loss: {avg_train_loss:.3f}, Validation Loss: {avg_val_loss:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d28ec7-a042-44a5-a713-e0787d434376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy of the network on the 10000 test images: 73.31%\n"
     ]
    }
   ],
   "source": [
    "net_nodropout.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = net_nodropout(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final Accuracy of the network on the 10000 test images: {final_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea9f23-a182-4459-8a63-2626f3e49fcf",
   "metadata": {},
   "source": [
    "Problem 2 (50 pts)\r\n",
    "\r\n",
    "The baseline model we did in lectures is called ResNet-11. Build a new version of ResNet (ResNet-18). Train it on CIFAR-10. Plot the training loss, validation loss, and validation accuracy. Compare the classification accuracy, and model size across the two versions of ResNet (11, 18). How does the complexity grow as you increase the network depth?\r\n",
    "\r\n",
    "You can find some references for ResNet 18 here:\r\n",
    "\r\n",
    "https://www.kaggle.com/code/ivankunyankin/resnet18-from-scratch-using-pytorchLinks to an external site.\r\n",
    "\r\n",
    "Explore the dropout option for the two networks and report your training results and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42eb256-aa30-4bc2-810d-5445ab3924ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1,Training Loss: 1.476, Validation Loss: 1.212\n",
      "Epoch 2,Training Loss: 0.984, Validation Loss: 0.858\n",
      "Epoch 3,Training Loss: 0.744, Validation Loss: 0.804\n",
      "Epoch 4,Training Loss: 0.569, Validation Loss: 0.736\n",
      "Epoch 5,Training Loss: 0.423, Validation Loss: 0.864\n",
      "Epoch 6,Training Loss: 0.297, Validation Loss: 0.857\n",
      "Epoch 7,Training Loss: 0.202, Validation Loss: 0.783\n",
      "Epoch 8,Training Loss: 0.134, Validation Loss: 1.040\n",
      "Epoch 9,Training Loss: 0.099, Validation Loss: 0.909\n",
      "Epoch 10,Training Loss: 0.085, Validation Loss: 0.993\n",
      "Epoch 11,Training Loss: 0.069, Validation Loss: 1.083\n",
      "Epoch 12,Training Loss: 0.043, Validation Loss: 0.980\n",
      "Epoch 13,Training Loss: 0.030, Validation Loss: 0.911\n",
      "Epoch 14,Training Loss: 0.025, Validation Loss: 0.892\n",
      "Epoch 15,Training Loss: 0.018, Validation Loss: 0.869\n",
      "Epoch 16,Training Loss: 0.016, Validation Loss: 0.912\n",
      "Epoch 17,Training Loss: 0.022, Validation Loss: 1.081\n",
      "Epoch 18,Training Loss: 0.029, Validation Loss: 0.992\n",
      "Epoch 19,Training Loss: 0.016, Validation Loss: 1.007\n",
      "Epoch 20,Training Loss: 0.011, Validation Loss: 0.933\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10, include_dropout=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5) if include_dropout else nn.Identity()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18(include_dropout=False):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], include_dropout=include_dropout)\n",
    "\n",
    "# CIFAR-10 data loading\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Model, criterion, optimizer\n",
    "net = resnet18(include_dropout=True).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    net.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "\n",
    "\n",
    "    # Validation phase\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    print(f'Epoch {epoch + 1},Training Loss: {avg_train_loss:.3f}, Validation Loss: {avg_val_loss:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a787b692-9b6d-4b2a-86a6-47509f6d40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy of the network on the 10000 test images: 79.93%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final Accuracy of the network on the 10000 test images: {final_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302eb2fb-511a-4a12-ae77-3d55140d9fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Training Loss: 1.469, Validation Loss: 1.136\n",
      "Epoch 2,Training Loss: 0.976, Validation Loss: 0.910\n",
      "Epoch 3,Training Loss: 0.725, Validation Loss: 0.767\n",
      "Epoch 4,Training Loss: 0.548, Validation Loss: 0.721\n",
      "Epoch 5,Training Loss: 0.407, Validation Loss: 0.753\n",
      "Epoch 6,Training Loss: 0.287, Validation Loss: 0.754\n",
      "Epoch 7,Training Loss: 0.195, Validation Loss: 1.064\n",
      "Epoch 8,Training Loss: 0.132, Validation Loss: 1.017\n",
      "Epoch 9,Training Loss: 0.098, Validation Loss: 1.007\n",
      "Epoch 10,Training Loss: 0.081, Validation Loss: 0.933\n",
      "Epoch 11,Training Loss: 0.070, Validation Loss: 1.097\n",
      "Epoch 12,Training Loss: 0.052, Validation Loss: 0.906\n",
      "Epoch 13,Training Loss: 0.039, Validation Loss: 0.848\n",
      "Epoch 14,Training Loss: 0.025, Validation Loss: 0.851\n",
      "Epoch 15,Training Loss: 0.019, Validation Loss: 0.895\n",
      "Epoch 16,Training Loss: 0.012, Validation Loss: 0.841\n",
      "Epoch 17,Training Loss: 0.010, Validation Loss: 0.822\n",
      "Epoch 18,Training Loss: 0.012, Validation Loss: 0.837\n",
      "Epoch 19,Training Loss: 0.008, Validation Loss: 0.822\n",
      "Epoch 20,Training Loss: 0.005, Validation Loss: 0.834\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Model, criterion, optimizer\n",
    "net_without_dropout = resnet18(include_dropout=True).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_without_dropout.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    net_without_dropout .train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net_without_dropout (inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(trainloader)\n",
    "\n",
    "\n",
    "    # Validation phase\n",
    "    net_without_dropout .eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].cuda(), data[1].cuda()\n",
    "            outputs = net_without_dropout (images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    print(f'Epoch {epoch + 1},Training Loss: {avg_train_loss:.3f}, Validation Loss: {avg_val_loss:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18574f5-613d-4c27-add2-dff8f4cf10ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy of the network on the 10000 test images: 81.29%\n"
     ]
    }
   ],
   "source": [
    " net_without_dropout.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs =  net_without_dropout(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * correct / total\n",
    "print(f'Final Accuracy of the network on the 10000 test images: {final_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
