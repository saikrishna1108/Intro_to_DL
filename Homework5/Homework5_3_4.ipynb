{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c3381f-e364-452e-9d89-a8cc3013f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc91fbf9-b089-4515-b113-fe74d8fc3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_to_french = [\n",
    "    (\"I am cold\", \"J'ai froid\"),\n",
    "    (\"You are tired\", \"Tu es fatigué\"),\n",
    "    (\"He is hungry\", \"Il a faim\"),\n",
    "    (\"She is happy\", \"Elle est heureuse\"),\n",
    "    (\"We are friends\", \"Nous sommes amis\"),\n",
    "    (\"They are students\", \"Ils sont étudiants\"),\n",
    "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
    "    (\"The sun is shining\", \"Le soleil brille\"),\n",
    "    (\"We love music\", \"Nous aimons la musique\"),\n",
    "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
    "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
    "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
    "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
    "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
    "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
    "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
    "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
    "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
    "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
    "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
    "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
    "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
    "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
    "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
    "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
    "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
    "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
    "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
    "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
    "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
    "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
    "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
    "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
    "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
    "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
    "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
    "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
    "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
    "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
    "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
    "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
    "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
    "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
    "    (\"The baby cries\", \"Le bébé pleure\"),\n",
    "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
    "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
    "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
    "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
    "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
    "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
    "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
    "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
    "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
    "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
    "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
    "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
    "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
    "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
    "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
    "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
    "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
    "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
    "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
    "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
    "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
    "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
    "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
    "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
    "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
    "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
    "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
    "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
    "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
    "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
    "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
    "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
    "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
    "]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3815893-45e3-4d21-a368-085d458e1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Constants for special tokens\n",
    "SOS_token = 0  # Start Of Sequence Token\n",
    "EOS_token = 1  # End Of Sequence Token\n",
    "french_to_english = [(french, english) for english, french in english_to_french]\n",
    "\n",
    "# Word to index mapping for reversed dataset\n",
    "word_to_index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
    "for pair in french_to_english:\n",
    "    for word in pair[0].split() + pair[1].split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "\n",
    "# Dataset class for handling translation data\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataset, word_to_index):\n",
    "        self.dataset = dataset\n",
    "        self.word_to_index = word_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_sentence, input_sentence = self.dataset[idx]  # Notice target and input are reversed\n",
    "        input_indices = [self.word_to_index[word] for word in input_sentence.split()] + [EOS_token]\n",
    "        target_indices = [self.word_to_index[word] for word in target_sentence.split()] + [EOS_token]\n",
    "        return torch.tensor(input_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    input_tensors, target_tensors = zip(*batch)\n",
    "    input_tensors_padded = pad_sequence(input_tensors, batch_first=True, padding_value=EOS_token)\n",
    "    target_tensors_padded = pad_sequence(target_tensors, batch_first=True, padding_value=EOS_token)\n",
    "    return input_tensors_padded, target_tensors_padded\n",
    "\n",
    "# Transformer Model\n",
    "class TranslationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=4, num_heads=4, dropout=0.1):\n",
    "        super(TranslationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=hidden_size * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        embedded_input = self.embedding(input)\n",
    "        embedded_target = self.embedding(target)\n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(target.size(1)).to(target.device)\n",
    "        transformer_output = self.transformer(embedded_input, embedded_target, tgt_mask=tgt_mask)\n",
    "        output = self.fc_out(transformer_output)\n",
    "        return output\n",
    "\n",
    "# Train and Evaluate function\n",
    "def train_and_evaluate(model, dataloader, optimizer, criterion, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        for input_tensor, target_tensor in dataloader:\n",
    "            input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_tensor, target_tensor[:, :-1])\n",
    "            output_flat = output.view(-1, output.size(-1))\n",
    "            target_flat = target_tensor[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output_flat, target_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output_flat, 1)\n",
    "            train_correct += (predicted == target_flat).sum().item()\n",
    "            train_total += target_flat.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss / len(dataloader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "\n",
    "        # Evaluate on the same dataset\n",
    "        model.eval()\n",
    "        eval_loss, eval_correct, eval_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for input_tensor, target_tensor in dataloader:\n",
    "                input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "                output = model(input_tensor, target_tensor[:, :-1])\n",
    "                output_flat = output.view(-1, output.size(-1))\n",
    "                target_flat = target_tensor[:, 1:].contiguous().view(-1)\n",
    "\n",
    "                loss = criterion(output_flat, target_flat)\n",
    "                eval_loss += loss.item()\n",
    "                _, predicted = torch.max(output_flat, 1)\n",
    "                eval_correct += (predicted == target_flat).sum().item()\n",
    "                eval_total += target_flat.size(0)\n",
    "\n",
    "        avg_eval_loss = eval_loss / len(dataloader)\n",
    "        eval_accuracy = eval_correct / eval_total\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Train Accuracy = {train_accuracy:.4f}, '\n",
    "                  f'Eval Loss = {avg_eval_loss:.4f}, Eval Accuracy = {eval_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c88d8f3f-405b-48d6-92dc-72766e9949d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 5.9498, Train Accuracy = 0.0142, Eval Loss = 5.7123, Eval Accuracy = 0.0506\n",
      "Epoch 11: Train Loss = 4.7943, Train Accuracy = 0.0686, Eval Loss = 4.6019, Eval Accuracy = 0.0789\n",
      "Epoch 21: Train Loss = 3.9450, Train Accuracy = 0.1579, Eval Loss = 3.6112, Eval Accuracy = 0.2247\n",
      "Epoch 31: Train Loss = 3.2895, Train Accuracy = 0.2716, Eval Loss = 2.8426, Eval Accuracy = 0.3482\n",
      "Epoch 41: Train Loss = 2.7172, Train Accuracy = 0.3576, Eval Loss = 2.2321, Eval Accuracy = 0.4109\n",
      "Epoch 51: Train Loss = 2.1923, Train Accuracy = 0.4190, Eval Loss = 1.7210, Eval Accuracy = 0.5173\n",
      "Epoch 61: Train Loss = 1.7829, Train Accuracy = 0.4990, Eval Loss = 1.2854, Eval Accuracy = 0.5243\n",
      "Epoch 71: Train Loss = 1.3866, Train Accuracy = 0.5223, Eval Loss = 0.9283, Eval Accuracy = 0.5405\n",
      "Epoch 81: Train Loss = 1.0863, Train Accuracy = 0.5364, Eval Loss = 0.6754, Eval Accuracy = 0.5506\n",
      "Epoch 91: Train Loss = 0.8561, Train Accuracy = 0.5385, Eval Loss = 0.4934, Eval Accuracy = 0.5747\n",
      "Epoch 101: Train Loss = 0.6859, Train Accuracy = 0.5486, Eval Loss = 0.3471, Eval Accuracy = 0.5747\n",
      "Epoch 111: Train Loss = 0.5345, Train Accuracy = 0.5526, Eval Loss = 0.2541, Eval Accuracy = 0.5526\n",
      "Epoch 121: Train Loss = 0.4285, Train Accuracy = 0.5526, Eval Loss = 0.1885, Eval Accuracy = 0.5526\n",
      "Epoch 131: Train Loss = 0.3396, Train Accuracy = 0.5676, Eval Loss = 0.1450, Eval Accuracy = 0.5526\n",
      "Epoch 141: Train Loss = 0.2642, Train Accuracy = 0.5526, Eval Loss = 0.1092, Eval Accuracy = 0.5526\n",
      "Epoch 151: Train Loss = 0.2253, Train Accuracy = 0.5526, Eval Loss = 0.0876, Eval Accuracy = 0.5526\n",
      "Epoch 161: Train Loss = 0.1939, Train Accuracy = 0.5747, Eval Loss = 0.0709, Eval Accuracy = 0.5526\n",
      "Epoch 171: Train Loss = 0.1601, Train Accuracy = 0.5526, Eval Loss = 0.0589, Eval Accuracy = 0.5676\n",
      "Epoch 181: Train Loss = 0.1413, Train Accuracy = 0.5526, Eval Loss = 0.0499, Eval Accuracy = 0.5747\n",
      "Epoch 191: Train Loss = 0.1271, Train Accuracy = 0.5526, Eval Loss = 0.0426, Eval Accuracy = 0.5747\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "vocab_size = len(word_to_index)\n",
    "hidden_size = 64\n",
    "model = TranslationModel(vocab_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"EOS\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# DataLoader\n",
    "dataset = TranslationDataset(english_to_french, word_to_index)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "# Train and evaluate\n",
    "train_and_evaluate(model, dataloader, optimizer, criterion, 200, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55fc3cdd-42c5-4c72-af64-432aa01cff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 6.0734, Train Accuracy = 0.0016, Eval Loss = 5.8389, Eval Accuracy = 0.0076\n",
      "Epoch 11: Train Loss = 5.0505, Train Accuracy = 0.0488, Eval Loss = 4.8594, Eval Accuracy = 0.0540\n",
      "Epoch 21: Train Loss = 4.2762, Train Accuracy = 0.0983, Eval Loss = 3.8888, Eval Accuracy = 0.1221\n",
      "Epoch 31: Train Loss = 3.5450, Train Accuracy = 0.1589, Eval Loss = 3.0969, Eval Accuracy = 0.2409\n",
      "Epoch 41: Train Loss = 2.8714, Train Accuracy = 0.2663, Eval Loss = 2.4060, Eval Accuracy = 0.3043\n",
      "Epoch 51: Train Loss = 2.3304, Train Accuracy = 0.3213, Eval Loss = 1.8383, Eval Accuracy = 0.3588\n",
      "Epoch 61: Train Loss = 1.9280, Train Accuracy = 0.3611, Eval Loss = 1.3805, Eval Accuracy = 0.4015\n",
      "Epoch 71: Train Loss = 1.5059, Train Accuracy = 0.3926, Eval Loss = 1.0237, Eval Accuracy = 0.4674\n",
      "Epoch 81: Train Loss = 1.1830, Train Accuracy = 0.4991, Eval Loss = 0.7539, Eval Accuracy = 0.4759\n",
      "Epoch 91: Train Loss = 0.9379, Train Accuracy = 0.4568, Eval Loss = 0.5360, Eval Accuracy = 0.4838\n",
      "Epoch 101: Train Loss = 0.7270, Train Accuracy = 0.4353, Eval Loss = 0.3907, Eval Accuracy = 0.4382\n",
      "Epoch 111: Train Loss = 0.5744, Train Accuracy = 0.4508, Eval Loss = 0.2865, Eval Accuracy = 0.4693\n",
      "Epoch 121: Train Loss = 0.4539, Train Accuracy = 0.4583, Eval Loss = 0.2080, Eval Accuracy = 0.4382\n",
      "Epoch 131: Train Loss = 0.3761, Train Accuracy = 0.4992, Eval Loss = 0.1590, Eval Accuracy = 0.4468\n",
      "Epoch 141: Train Loss = 0.3014, Train Accuracy = 0.4599, Eval Loss = 0.1213, Eval Accuracy = 0.4382\n",
      "Epoch 151: Train Loss = 0.2449, Train Accuracy = 0.4508, Eval Loss = 0.0940, Eval Accuracy = 0.4791\n",
      "Epoch 161: Train Loss = 0.2091, Train Accuracy = 0.4468, Eval Loss = 0.0793, Eval Accuracy = 0.4508\n",
      "Epoch 171: Train Loss = 0.1766, Train Accuracy = 0.4738, Eval Loss = 0.0656, Eval Accuracy = 0.4468\n",
      "Epoch 181: Train Loss = 0.1493, Train Accuracy = 0.4382, Eval Loss = 0.0538, Eval Accuracy = 0.4508\n",
      "Epoch 191: Train Loss = 0.1273, Train Accuracy = 0.4508, Eval Loss = 0.0474, Eval Accuracy = 0.4468\n",
      "Epoch 201: Train Loss = 0.1182, Train Accuracy = 0.4557, Eval Loss = 0.0389, Eval Accuracy = 0.4599\n",
      "Epoch 211: Train Loss = 0.1047, Train Accuracy = 0.4382, Eval Loss = 0.0333, Eval Accuracy = 0.4599\n",
      "Epoch 221: Train Loss = 0.0900, Train Accuracy = 0.4508, Eval Loss = 0.0300, Eval Accuracy = 0.4508\n",
      "Epoch 231: Train Loss = 0.0803, Train Accuracy = 0.4599, Eval Loss = 0.0260, Eval Accuracy = 0.4508\n",
      "Epoch 241: Train Loss = 0.0696, Train Accuracy = 0.4557, Eval Loss = 0.0228, Eval Accuracy = 0.4508\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "vocab_size = len(word_to_index)\n",
    "hidden_size = 64\n",
    "model = TranslationModel(vocab_size, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word_to_index[\"EOS\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = TranslationDataset(french_to_english, word_to_index)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "# Train and evaluate\n",
    "train_and_evaluate(model, dataloader, optimizer, criterion, 250, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
